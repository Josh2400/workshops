{
  "hash": "61ea3e132239abecf0aa4be9f2aa7eaf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"2 - Model optimization by tuning\"\nsubtitle: \"Getting More Out of Feature Engineering and Tuning for Machine Learning\"\nformat:\n  revealjs: \n    slide-number: true\n    footer: <https://workshops.tidymodels.org>\n    include-before-body: header.html\n    include-after-body: footer-annotations.html\n    theme: [default, tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk: \n    echo: true\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\n\n\n\n\n## Startup!  ![](hexes/tidymodels.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(probably)\nlibrary(desirability2)\n\ntidymodels_prefer()\ntheme_set(theme_bw())\noptions(pillar.advice = FALSE, pillar.min_title_chars = Inf)\n\n# check torch:\nif (torch::torch_is_installed()) {\n  library(torch)\n}\n\n# Load our example data for this section\n\"https://raw.githubusercontent.com/tidymodels/\" |> \n  paste0(\"workshops/main/slides/class_data.RData\") |> \n  url() |> \n  load()\n```\n:::\n\n\n\n## Where we are ![](hexes/rsample.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(429)\nsim_split <- initial_split(class_data, prop = 0.75, strata = class)\nsim_train <- training(sim_split)\nsim_test  <- testing(sim_split)\n\nset.seed(523)\nsim_rs <- vfold_cv(sim_train, v = 10, strata = class)\n```\n:::\n\n\n\n# Neural networks {background-color=\"#BDE9C9FF\"}\n\n## The brulee package ![](hexes/brulee.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nSeveral packages exist for this, but we‚Äôll use the brulee package, which relies on the torch deep learning framework. \n\n<br> \n\nLet's load the package and look at the documentation for the function that we will use: \n\n<br> \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This might trigger a torch install: \nlibrary(brulee)\n# ?brulee_mlp\n```\n:::\n\n\n\n([HTML docs](https://brulee.tidymodels.org/reference/brulee_mlp.html) are nice too)\n\n## Notable arguments Part 1 ![](hexes/brulee.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nModel Structure: \n\n- `hidden_units`: the primary way to specify model complexity.\n- `activation`: the name of the nonlinear function used to connect the predictors to the hidden layer. \n\n. . . \n\nLoss Function:\n\n- `penalty`: amount of regularization used to prevent overfitting. \n- `mixture`: the proportion of L1 and L2 penalties. \n- `validation`: proportion of data to leave out to assess early stopping.\n\n\n## Notable arguments Part 2 ![](hexes/brulee.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nOptimization:\n\n- `optimizer`: the type of gradient-based optimization.\n- `epochs`: how many passes through the entire data set (i.e., iterations).\n- `stop_iter`: number of bad iterations before stopping.\n- `learn_rate`: how fast does gradient descent move? \n- `rate_schedule`: should the learning rate change over epochs?\n- `batch_size`: for stochastic gradient descent.\n\n<br> \n\nThat's a lot üò©\n\n\n## Cost-sensitive learning ![](hexes/brulee.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nOne other option: `class_weights`: amount to upweight the minority class (`event`) when computing the objective function (cross-entropy).\n\n<br> \n\nWe have a moderate class imbalance, and we'll use this argument to deal with it. \n\n<br> \n\nThis will push the minority class probability estimates to be _more_ accurate/[calibrated](https://aml4td.org/chapters/cls-metrics.html#sec-cls-calibration). _Overall_ the model will be less effective; this assumes the minority class is the class of interest. \n\n\n## A single model ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/parsnip.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} ![](hexes/brulee.png){.absolute top=-20 right=192 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2|3|4|6-8|10|12-14|\"}\nnnet_ex_spec <- \n  mlp(hidden_units = 20, penalty = 0.01, learn_rate = 0.005, epochs = 100) |> \n  set_engine(\"brulee\", class_weights = 3, stop_iter = 10) |> \n  set_mode(\"classification\")\n\nrec <- \n  recipe(class ~ ., data = sim_train) |> \n  step_normalize(all_numeric_predictors())\n\nnnet_ex_wflow <- workflow(rec, nnet_ex_spec)\n\n# Fit on the first fold's 90% analysis set\nset.seed(147)\nnnet_ex_fit <- fit(nnet_ex_wflow, data = analysis(sim_rs$splits[[1]]))\n```\n:::\n\n\n\n\n## Did it converge?  ![](hexes/ggplot2.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/brulee.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|2-3|4|\"}\nnnet_ex_fit |>\n  # pull out the brulee fit:\n  extract_fit_engine() |>\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/nnet-converge-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"30%\"}\nThe y-axis statistics are computed on the held-out predictions at each iteration.\n\nThe vertical green line shows that early stopping occurred. \n:::\n\n::::\n\n## Did it work?   ![](hexes/yardstick.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/rsample.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/brulee.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} ![](hexes/broom.png){.absolute top=-20 right=192 width=\"64\" height=\"74.24\"} \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|2|3|5-6|\"}\nassessment_data <- assessment(sim_rs$splits[[1]])\ncls_mtr <- metric_set(brier_class, roc_auc, sensitivity, specificity)\nholdout_pred <- augment(nnet_ex_fit, assessment_data) \n\n# Performance metrics\nholdout_pred |> cls_mtr(class, estimate = .pred_class, .pred_event)\n#> # A tibble: 4 √ó 3\n#>   .metric     .estimator .estimate\n#>   <chr>       <chr>          <dbl>\n#> 1 sensitivity binary        0.706 \n#> 2 specificity binary        0.940 \n#> 3 brier_class binary        0.0701\n#> 4 roc_auc     binary        0.932\n```\n:::\n\n\n\nKind of? \n\nIf sensitivity is important, then the model is moderately successful.  \n\n## Calibration\n\nCalibration is a property of individual predictions. A well-calibrated probability occurs _in the wild_ at the same rate as the estimate. \n\nThe Brier score is the closest we can come to estimating it:\n\n$$\nBrier = \\frac{1}{NC}\\sum_{i=1}^N\\sum_{k=1}^C (y_{ik} - \\hat{p}_{ik})^2\n$$\n\nZero is best and, for two classes, values above 0.25 are bad. \n\n::: {.absolute bottom=0 right=0}\n[AML4TD](https://aml4td.org/chapters/cls-metrics.html#sec-brier)\n:::\n\n\n## Calibration Plots![](hexes/probably.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2|3|4|5-6|\"}\nholdout_pred |>\n  cal_plot_windowed(\n    truth = class,\n    estimate = .pred_event,\n    window_size = 0.2,\n    step_size = 0.025\n  )\n```\n:::\n\n\n\n<br><br>\n\n\nüò± \n\nThis is partly due to the small sample size. \n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/nnet-cal-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n:::\n\n::::\n\n::: {.absolute bottom=0 right=0}\n[AML4TD](https://aml4td.org/chapters/cls-metrics.html#sec-cls-calibration)\n:::\n\n\n\n# Optimizing Models via Tuning Parameters {background-color=\"#D04E59FF\"}\n\n## Tuning parameters\n\nSome model or preprocessing parameters cannot be estimated directly from the data.\n\n. . .\n\nSome examples:\n\n- Tree depth in decision trees\n- Number of neighbors in a K-nearest neighbor model\n\n# Activation function in neural networks?\n\nSigmoidal functions, ReLu, etc.\n\n::: fragment\nYes, it is a tuning parameter.\n‚úÖ\n:::\n\n# Number of PCA columns to generate for feature extraction?\n\n::: fragment\nYes, it is a _preprocessing_ tuning parameter.\n‚úÖ\n:::\n\n# The validation set size?\n\n::: fragment\nNope!\n‚ùå\n:::\n\n\n# Bayesian priors for model parameters?\n\n::: fragment\nHmmmm, probably not.\nThese are based on prior belief.\n‚ùå\n:::\n\n# The class probability cutoff?\n\nThis is a value $C$ used to threshold $Pr[Class = 1]  \\ge C$. \n\nFor two classes, the default is $C = 1/2$. \n\n::: fragment\nYes, it is a _postprocessing_ tuning parameter.\n‚úÖ\n:::\n\n\n# The random seed?\n\n::: fragment\nNope. It is not. \n‚ùå\n:::\n\n## Optimize tuning parameters\n\n- Try different values and measure their performance.\n\n. . .\n\n- Find good values for these parameters.\n\n. . .\n\n- Once the value(s) of the parameter(s) are determined, a model can be finalized by fitting the model to the entire training set.\n\n\n## Tagging parameters for tuning  ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nWith tidymodels, you can mark the parameters that you want to optimize with a value of `tune()`. \n\n<br>\n\nThe function itself just returns... itself: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune()\n#> tune()\nstr(tune())\n#>  language tune()\n\n# optionally add a label\ntune(\"I hope that the workshop is going well\")\n#> tune(\"I hope that the workshop is going well\")\n```\n:::\n\n\n\n. . . \n\nFor example...\n\n\n## Optimizing the neural network ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/recipes.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2-3|4|\"}\nnnet_spec <- \n  mlp(hidden_units = tune(), penalty = tune(), learn_rate = tune(), \n      epochs = 100, activation = tune()) |> \n  set_engine(\"brulee\", class_weights = tune(), stop_iter = 10) |> \n  set_mode(\"classification\")\n\nnnet_wflow <- workflow(rec, nnet_spec)\nnnet_wflow\n#> ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n#> Preprocessor: Recipe\n#> Model: mlp()\n#> \n#> ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> 1 Recipe Step\n#> \n#> ‚Ä¢ step_normalize()\n#> \n#> ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Single Layer Neural Network Model Specification (classification)\n#> \n#> Main Arguments:\n#>   hidden_units = tune()\n#>   penalty = tune()\n#>   epochs = 100\n#>   activation = tune()\n#>   learn_rate = tune()\n#> \n#> Engine-Specific Arguments:\n#>   class_weights = tune()\n#>   stop_iter = 10\n#> \n#> Computational engine: brulee\n```\n:::\n\n\n\n\n## Optimize tuning parameters\n\nThe two main strategies for optimization are:\n\n- **Grid search**, which tests a pre-defined set of candidate values.\n\n- **Iterative search**, which suggests/estimates new values of candidate parameters to evaluate.\n\n\n. . .\n\nWe won't be discussing iterative search methods in the regular notes. But you can learn more in [AML4TD](https://aml4td.org/chapters/iterative-search.html) or in the extra slides for this subject. \n\n## Grid search\n\nA small grid of points trying to minimize the error via learning rate: \n\n\n![](images/small_init.svg){fig-align=\"center\" width=60%}\n\n\n## Grid search\n\nIn reality, we would probably sample the space more densely: \n\n![](images/grid_points.svg){fig-align=\"center\" width=60%}\n\n\n## Iterative Search\n\nWe could start with a few points and search the space:\n\n![](animations/anime_seq.gif){fig-align=\"center\" width=60%}\n\n# Grid Search {background-color=\"#FAE093FF\"}\n\n## Parameters\n\n-   The tidymodels framework provides pre-defined information on tuning parameters (such as their type, range, transformations, etc.).\n\n-   The `extract_parameter_set_dials()` function extracts these tuning parameters and the info.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_param <- \n  nnet_wflow |> \n  extract_parameter_set_dials() \nnnet_param  \n#> Collection of 5 parameters for tuning\n#> \n#>     identifier          type    object\n#>   hidden_units  hidden_units nparam[+]\n#>        penalty       penalty nparam[+]\n#>     activation    activation dparam[+]\n#>     learn_rate    learn_rate nparam[+]\n#>  class_weights class_weights nparam[+]\n#> \n```\n:::\n\n\n\n## Different types of grids ![](hexes/dials.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}  {.annotation}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/grid-types-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n[Space-filling designs](https://aml4td.org/chapters/grid-search.html#sec-irregular-grid) (SFD) attempt to cover the parameter space without redundant candidates. We recommend these the most, and they are the default. \n\n## Extract and update parameters ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/dials.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}  {.annotation}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_param <- \n  nnet_param |> \n  update(class_weights = class_weights(c(1, 50)))\n  \n  nnet_param  \n#> Collection of 5 parameters for tuning\n#> \n#>     identifier          type    object\n#>   hidden_units  hidden_units nparam[+]\n#>        penalty       penalty nparam[+]\n#>     activation    activation dparam[+]\n#>     learn_rate    learn_rate nparam[+]\n#>  class_weights class_weights nparam[+]\n#> \n```\n:::\n\n\n\n\n## Neural network tuning ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/dials.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"}   {.annotation}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|5|8|10|11|12|\"}\nctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)\n\nset.seed(12)\nnnet_res <-\n  nnet_wflow |>\n  tune_grid(\n    resamples = sim_rs,\n    grid = 25,\n    # The options below are not required by default\n    param_info = nnet_param, \n    control = ctrl,\n    metrics = cls_mtr\n  )\n```\n:::\n\n\n\n. . .\n\n<br>\n\n‚úã maybe don't run this just yet...\n\n::: notes\n-   `tune_grid()` is representative of tuning function syntax\n-   similar to `fit_resamples()`\n:::\n\n## Running in parallel  {.annotation}\n\n-   Grid search, combined with resampling, requires fitting a lot of models!\n\n-   These models don't depend on one another and can be run in parallel.\n\nWe can use the future or mirai packages to do this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncores <- parallelly::availableCores(logical = FALSE)\n```\n:::\n\n\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(future)\nplan(multisession, workers = cores)\n\n# Now call `tune_grid()`!\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mirai)\ndaemons(cores)\n\n# Now call `tune_grid()`!\n```\n:::\n\n\n:::\n:::\n\n\n\n\n\n\n\n## Distributing tasks \n\nWhen only tuning the model:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/resample-times-1.svg){fig-align='center' width=40%}\n:::\n:::\n\n\n\n## Running in parallel\n\nSpeed-ups are fairly linear up to the number of physical cores (10 here).\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/parallel-speedup-1.svg){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n:::notes\nFaceted on the expensiveness of preprocessing used.\n:::\n\n## Running in parallel\n\nWe'll use mirai as our parallel backend for our notes. \n\n<br>\n\nUsing 10 cores with mirai, time to execute the previous `tune_grid()` call was reduced from 256s to 45s, a speed-up of 5.7-fold.\n\n<br>\n\nThe next slide deck (on racing) includes more examples of speed-ups for a different model. \n\n\n## Grid Search ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/dials.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_res \n#> # Tuning results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 √ó 5\n#>    splits             id     .metrics           .notes           .predictions\n#>    <list>             <chr>  <list>             <list>           <list>      \n#>  1 <split [1348/151]> Fold01 <tibble [100 √ó 9]> <tibble [3 √ó 4]> <tibble>    \n#>  2 <split [1349/150]> Fold02 <tibble [100 √ó 9]> <tibble [2 √ó 4]> <tibble>    \n#>  3 <split [1349/150]> Fold03 <tibble [100 √ó 9]> <tibble [2 √ó 4]> <tibble>    \n#>  4 <split [1349/150]> Fold04 <tibble [100 √ó 9]> <tibble [3 √ó 4]> <tibble>    \n#>  5 <split [1349/150]> Fold05 <tibble [100 √ó 9]> <tibble [2 √ó 4]> <tibble>    \n#>  6 <split [1349/150]> Fold06 <tibble [96 √ó 9]>  <tibble [5 √ó 4]> <tibble>    \n#>  7 <split [1349/150]> Fold07 <tibble [100 √ó 9]> <tibble [1 √ó 4]> <tibble>    \n#>  8 <split [1349/150]> Fold08 <tibble [100 √ó 9]> <tibble [5 √ó 4]> <tibble>    \n#>  9 <split [1350/149]> Fold09 <tibble [100 √ó 9]> <tibble [2 √ó 4]> <tibble>    \n#> 10 <split [1350/149]> Fold10 <tibble [100 √ó 9]> <tibble [3 √ó 4]> <tibble>    \n#> \n#> There were issues with some computations:\n#> \n#>   - Error(s) x1: 'best_epoch' should be an integer\n#>   - Warning(s) x1: Loss is NaN at epoch 1. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 10. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 11. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 12. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 13. Training is stopped.\n#>   - Warning(s) x2: Loss is NaN at epoch 2. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 3. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 4. Training is stopped.\n#>   - Warning(s) x3: Loss is NaN at epoch 5. Training is stopped.\n#>   - Warning(s) x2: Loss is NaN at epoch 6. Training is stopped.\n#>   - Warning(s) x5: Loss is NaN at epoch 7. Training is stopped.\n#>   - Warning(s) x7: Loss is NaN at epoch 8. Training is stopped.\n#>   - Warning(s) x1: Loss is NaN at epoch 9. Training is stopped.\n#> \n#> Run `show_notes(.Last.tune.result)` for more information.\n```\n:::\n\n\n\n\n## Grid results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(nnet_res)\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/sim-nnet-all-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Brier results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(nnet_res, metric = \"brier_class\") + \n  facet_grid(. ~ name, scale = \"free_x\") + \n  lims(y = c(0.04, 0.22)) # no tanh\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/sim-nnet-brier-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## ROC curve results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(nnet_res, metric = \"roc_auc\") + \n  facet_grid(. ~ name, scale = \"free_x\") + \n  lims(y = c(0.83, 0.97)) # no tanh\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/sim-nnet-roc-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Sensitivity/Specificity results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(nnet_res, metric = c(\"sensitivity\", \"specificity\"))\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/sim-nnet-two-class-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Grid results\n\n - tanh activation üëéüëé\n - As class weight ‚¨ÜÔ∏è:\n    - sensitivity ‚¨ÜÔ∏è\n    - specificity ‚¨áÔ∏è‚¨áÔ∏è \n    - Brier: ‚¨ÜÔ∏è \n    - ROC AUC: ü§∑\n\n# Choosing Tuning Parameters {background-color=\"#D04E59FF\"}\n\n## Tuning results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|6-9|10-13|\"}\ncollect_metrics(nnet_res) |> \n  relocate(.metric, mean) \n#> # A tibble: 100 √ó 11\n#>    .metric      mean hidden_units    penalty activation learn_rate class_weights\n#>    <chr>       <dbl>        <int>      <dbl> <chr>           <dbl>         <dbl>\n#>  1 brier_class 0.216            2 0.00000147 elu           0.0962           17.3\n#>  2 roc_auc     0.834            2 0.00000147 elu           0.0962           17.3\n#>  3 sensitivity 0.905            2 0.00000147 elu           0.0962           17.3\n#>  4 specificity 0.642            2 0.00000147 elu           0.0962           17.3\n#>  5 brier_class 0.209            4 0.000464   tanhshrink    0.0736           31.6\n#>  6 roc_auc     0.905            4 0.000464   tanhshrink    0.0736           31.6\n#>  7 sensitivity 0.935            4 0.000464   tanhshrink    0.0736           31.6\n#>  8 specificity 0.641            4 0.000464   tanhshrink    0.0736           31.6\n#>  9 brier_class 0.212            6 0.00000383 relu          0.00224          41.8\n#> 10 roc_auc     0.932            6 0.00000383 relu          0.00224          41.8\n#> # ‚Ñπ 90 more rows\n#> # ‚Ñπ 4 more variables: .estimator <chr>, n <int>, std_err <dbl>, .config <chr>\n```\n:::\n\n\n\n## Tuning results ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(nnet_res, summarize = FALSE) |> \n  relocate(.metric, .estimate)\n#> # A tibble: 996 √ó 10\n#>    .metric     .estimate id     hidden_units    penalty activation learn_rate\n#>    <chr>           <dbl> <chr>         <int>      <dbl> <chr>           <dbl>\n#>  1 sensitivity    0.824  Fold01            2 0.00000147 elu            0.0962\n#>  2 specificity    0.910  Fold01            2 0.00000147 elu            0.0962\n#>  3 brier_class    0.0659 Fold01            2 0.00000147 elu            0.0962\n#>  4 roc_auc        0.967  Fold01            2 0.00000147 elu            0.0962\n#>  5 sensitivity    1      Fold02            2 0.00000147 elu            0.0962\n#>  6 specificity    0.474  Fold02            2 0.00000147 elu            0.0962\n#>  7 brier_class    0.305  Fold02            2 0.00000147 elu            0.0962\n#>  8 roc_auc        0.797  Fold02            2 0.00000147 elu            0.0962\n#>  9 sensitivity    0.941  Fold03            2 0.00000147 elu            0.0962\n#> 10 specificity    0.910  Fold03            2 0.00000147 elu            0.0962\n#> # ‚Ñπ 986 more rows\n#> # ‚Ñπ 3 more variables: class_weights <dbl>, .estimator <chr>, .config <chr>\n```\n:::\n\n\n\n## Choose a parameter combination ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|6|\"}\nshow_best(nnet_res, metric = \"brier_class\") |> \n  relocate(.metric, mean) \n#> # A tibble: 5 √ó 11\n#>   .metric       mean hidden_units    penalty activation learn_rate class_weights\n#>   <chr>        <dbl>        <int>      <dbl> <chr>           <dbl>         <dbl>\n#> 1 brier_class 0.0468           36    2.61e-5 elu           0.0562           3.04\n#> 2 brier_class 0.0541           16    8.25e-8 log_sigmo‚Ä¶    0.00171          5.08\n#> 3 brier_class 0.0642           40    2.15e-2 tanh          0.00293          7.12\n#> 4 brier_class 0.0674           48    1.78e-9 relu          0.0112          11.2 \n#> 5 brier_class 0.0689           26    4.64e-9 relu          0.482            9.17\n#> # ‚Ñπ 4 more variables: .estimator <chr>, n <int>, std_err <dbl>, .config <chr>\n```\n:::\n\n\n\n## Choose a parameter combination ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nCreate your own tibble for final parameters or use one of the `tune::select_*()` functions:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|6|8-10|14-17|\"}\nnnet_best <- select_best(nnet_res, metric = \"brier_class\")\nnnet_best\n#> # A tibble: 1 √ó 6\n#>   hidden_units   penalty activation learn_rate class_weights .config         \n#>          <int>     <dbl> <chr>           <dbl>         <dbl> <chr>           \n#> 1           36 0.0000261 elu            0.0562          3.04 pre0_mod18_post0\n\ncollect_metrics(nnet_res) |> \n  inner_join(nnet_best) |> \n  select(.metric, mean)\n#> # A tibble: 4 √ó 2\n#>   .metric       mean\n#>   <chr>        <dbl>\n#> 1 brier_class 0.0468\n#> 2 roc_auc     0.967 \n#> 3 sensitivity 0.792 \n#> 4 specificity 0.958\n```\n:::\n\n\n\n## Checking (Approximate) Calibration ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/probably.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nnnet_holdout_pred <-\n  nnet_res |> \n  collect_predictions(\n    parameters = nnet_best\n  )\n\nnnet_holdout_pred |>\n  cal_plot_windowed(\n    truth = class,\n    estimate = .pred_event,\n    window_size = 0.2,\n    step_size = 0.025,\n  )\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/nnet-cal-plot-1.svg){width=90%}\n:::\n:::\n\n\n\n\n::: notes\nThis plot _pools_ the out-of-sample predictions. Our Brier estimate is the mean of 10 data sets.\n\nThe curve is approximate for that reason. \n:::\n\n\n## Multiple goals\n\nOptimizing the Brier score optimizes for accuracy and calibration of the class probabilities. \n\n<br> \n\nThat's counter-productive to finding the rare class \"event\" events.\n\n<br>\n\nCan we find a way to optimize multiple metrics at once? \n\n<br> \n\nThere are a few ways, and we'll focus on [desirability functions](https://aml4td.org/chapters/cls-metrics.html#sec-cls-multi-objectives). \n\n## Desirability functions\n\nWe create simple functions to translate our variable to [0, 1]; 1.0 is most desirable.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/three-desirability-examples-1.svg){width=70%}\n:::\n:::\n\n\n\nWe can combine them with a geometric mean. \n\n\n## Multimetric optimization ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|3|4|5|11|12-13|\"}\nshow_best_desirability(\n  nnet_res, \n  maximize(sensitivity),\n  minimize(brier_class),\n  constrain(specificity, low = 0.8, high = 1.0)\n) |> \n  relocate(class_weights, sensitivity, specificity, brier_class, .d_overall) \n#> # A tibble: 5 √ó 14\n#>   class_weights sensitivity specificity brier_class .d_overall hidden_units\n#>           <dbl>       <dbl>       <dbl>       <dbl>      <dbl>        <int>\n#> 1         29.6        0.947       0.859      0.0956      0.941           38\n#> 2         50          0.953       0.841      0.112       0.934           30\n#> 3         45.9        0.970       0.802      0.128       0.933           20\n#> 4          7.12       0.893       0.914      0.0642      0.928           40\n#> 5         11.2        0.882       0.917      0.0674      0.919           48\n#> # ‚Ñπ 8 more variables: penalty <dbl>, activation <chr>, learn_rate <dbl>,\n#> #   .config <chr>, roc_auc <dbl>, .d_max_sensitivity <dbl>,\n#> #   .d_min_brier_class <dbl>, .d_box_specificity <dbl>\n```\n:::\n\n\n\n\n## However... ![](hexes/tune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/probably.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nmore_sens <-\n  select_best_desirability(\n    nnet_res,\n    maximize(sensitivity),\n    minimize(brier_class),\n    constrain(specificity, low = 0.8, high = 1.0)\n  )\n\nnnet_res |>\n  collect_predictions(\n    parameters = more_sens\n  ) |>\n  cal_plot_windowed(\n    truth = class,\n    estimate = .pred_event,\n    window_size = 0.2,\n    step_size = 0.025,\n  )\n```\n\n::: {.cell-output-display}\n![](advanced-02-model-tuning_files/figure-revealjs/nnet-cal-plot-sens-1.svg){width=90%}\n:::\n:::\n\n\n\n\n::: notes\nThe curve hugging the bottom of the plot means that we are drastically _overestimating_ the probability of the \"event\" class relative to how often it occurs \"in the wild.\"\n\nThat's the point of cost-sensitive learning, but it's bad for calibration.\n\n:::\n\n## Conflicting goals\n\nThe problem here is that we are biasing the probability estimates so that we can predict more data to be the rare \"event\" class _using a default probability cutoff of 1/2_. \n\n<br> \n\nThat is compromising the overall model fit; our probabilities are not accurate.\n\n- If we don't use the class probability estimates, this is fine. \n\n<br>\n\nIn the _postprocessing_ slides, we'll examine an alternative approach that involves different kinds of tradeoffs. \n\n\n## Fitting a workflow ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\nLet's say that we want to train the model on the \"best\" parameter estimates.\n\nWe can use a tibble of tuning parameters and _splice_ them into the workflow in place of `tune()`: \n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|4|\"}\nset.seed(398)\nnnet_sens_fit <-\n  nnet_wflow |>\n  finalize_workflow(more_sens) |>\n  fit(sim_train)\n```\n:::\n\n\n:::\n\n::: {.column width=\"55%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nnnet_sens_fit |> extract_fit_engine()\n#> Multilayer perceptron\n#> \n#> elu activation,\n#> 38 hidden units,\n#> 1,256 model parameters\n#> 1,499 samples, 30 features, 2 classes \n#> class weights event=29.58333, no_event= 1.00000 \n#> weight decay: 1e-05 \n#> dropout proportion: 0 \n#> batch size: 1350 \n#> learn rate: 0.001 \n#> validation loss after 100 epochs: 0.142\n```\n:::\n\n\n:::\n\n::::\n\n\n## Ordering off of the menu ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"}\n\nIf we want to choose from the numerically best for an existing metric, there is a simpler function: \n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|4|\"}\nset.seed(398)\nmlp_brier_fit <-\n  nnet_res |>\n  fit_best(metric = \"brier_class\")\n```\n:::\n\n\n:::\n\n::: {.column width=\"55%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nmlp_brier_fit |> extract_fit_engine()\n#> Multilayer perceptron\n#> \n#> elu activation,\n#> 36 hidden units,\n#> 1,190 model parameters\n#> 1,499 samples, 30 features, 2 classes \n#> class weights event=3.041667, no_event=1.000000 \n#> weight decay: 2.610157e-05 \n#> dropout proportion: 0 \n#> batch size: 1350 \n#> learn rate: 0.05623413 \n#> validation loss after 6 epochs: 0.411\n```\n:::\n\n\n:::\n\n::::\n\n## Extracting Results  ![](hexes/workflows.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"} ![](hexes/tune.png){.absolute top=-20 right=64 width=\"64\" height=\"74.24\"} ![](hexes/tibble.png){.absolute top=-20 right=128 width=\"64\" height=\"74.24\"} ![](hexes/purrr.png){.absolute top=-20 right=192 width=\"64\" height=\"74.24\"} ![](hexes/dplyr.png){.absolute top=-20 right=256 width=\"64\" height=\"74.24\"}\n\nIf we want to know about the resampled workflow, we can write a function that can return information from `tune_grid()`. \n\n<br> \n\nFor example, this one can save the optimization process results: \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2-3|8|\"}\nextract_iter_hist <- function(wflow) {\n  require(tidymodels)\n  require(tibble)\n  wflow |>\n    extract_fit_engine() |>\n    pluck(\"loss\") |>\n    as_tibble_col(\"loss\") |>\n    mutate(epoch = row_number() - 1)\n}\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlp_brier_fit |> \n  extract_iter_hist() |> \n  slice(1:5)\n#> # A tibble: 5 √ó 2\n#>    loss epoch\n#>   <dbl> <dbl>\n#> 1 0.517     0\n#> 2 0.501     1\n#> 3 0.483     2\n#> 4 0.461     3\n#> 5 0.437     4\n```\n:::\n\n\n:::\n\n::::\n\n## Your turn {transition=\"slide-in\"}\n\n1. Read the docs for [`control_grid()`](https://tune.tidymodels.org/reference/control_grid.html), specifically the `extract` option.\n2. Create a control object that extracts the iteration history.\n3. Re-run `tune_grid()` with the same grid (or fewer grid points) and use the `control` option with the extraction function. \n4. Afterward use [`collect_extracts()`](https://tune.tidymodels.org/reference/collect_predictions.html) to get the results. \n5. Plot the iteration history for one or more grid points, coloring by the resample `id`. \n\nParallel processing will make this go more quickly. \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"racing-repeat\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">10</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\n## What's next ![](hexes/finetune.png){.absolute top=-20 right=0 width=\"64\" height=\"74.24\"}\n\nLet's look at _racing_: an old variation of grid search that adaptively processes the grid. \n\n<br> \n\nIf we are\n\n - initially screening _many_ models/preprocessors/postprocessors and/or\n - have a large grid\n \nThis can lead to remarkable speed-ups. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}