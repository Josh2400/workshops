---
title: "6 - Postprocessing - Classwork"
subtitle: "Getting More Out of Feature Engineering and Tuning for Machine Learning"
editor_options: 
  chunk_output_type: console
---

We recommend restarting R between each slide deck!

## Setup

```{r}
library(tidymodels)
library(important)
library(probably)
library(mirai)

# check torch:
if (torch::torch_is_installed()) {
  library(torch)
}

# Max's usual settings:
tidymodels_prefer()
theme_set(theme_bw())
options(
  pillar.advice = FALSE,
  pillar.min_title_chars = Inf
)
daemons(parallel::detectCores())

# Load our example data for this section
"https://raw.githubusercontent.com/tidymodels/" |>
  paste0("workshops/main/slides/class_data.RData") |>
  url() |>
  load()

set.seed(429)
sim_split <- initial_split(class_data, prop = 0.75, strata = class)
sim_train <- training(sim_split)
sim_test <- testing(sim_split)

set.seed(523)
sim_rs <- vfold_cv(sim_train, v = 10, strata = class)
```

## K-nearest neighbors

```{r}
rec <-
  recipe(class ~ ., data = sim_train) |>
  step_predictor_best(
    all_predictors(),
    score = "imp_rf",
    prop_terms = tune(),
    id = "filter"
  ) |>
  step_normalize(all_numeric_predictors())

knn_spec <-
  nearest_neighbor(neighbors = tune(), weight_func = tune()) |>
  set_mode("classification")

thrsh_tlr <-
  tailor() |>
  adjust_probability_threshold(threshold = tune())

knn_wflow <- workflow(rec, knn_spec, thrsh_tlr)

knn_param <-
  knn_wflow |>
  extract_parameter_set_dials() |>
  update(
    threshold = threshold(c(0.001, 0.1)),
    neighbors = neighbors(c(1, 50))
  )
```

## Tuning

```{r}
cls_mtr <- metric_set(brier_class, roc_auc, sensitivity, specificity)
ctrl <- control_grid(save_pred = TRUE, save_workflow = TRUE)

set.seed(12)
knn_res <-
  knn_wflow |>
  tune_grid(
    resamples = sim_rs,
    grid = 50,
    control = ctrl,
    metrics = cls_mtr,
    param_info = knn_param
  )
```

## Grid results `r hexes(c("tune"))`

```{r}
autoplot(knn_res)

## Brier results
autoplot(knn_res, metric = "brier_class") +
  facet_grid(. ~ name, scale = "free_x")

## ROC curve results
autoplot(knn_res, metric = "roc_auc") +
  facet_grid(. ~ name, scale = "free_x")

## Sensitivity/Specificity results
autoplot(knn_res, metric = c("sensitivity", "specificity"))
```

## Fit the model and get filter information

```{r}
knn_fit <- fit_best(knn_res, metric = "brier_class")
filter_info <-
  knn_fit |>
  extract_recipe() |>
  tidy(id = "filter")

filter_info
```

## Proceed to the test set -- Manual approach 

We already have our fitted model and, if we are happy with it:  

```{r}
test_pred <- augment(knn_fit, sim_test)
test_pred |> cls_mtr(class, estimate = .pred_class, .pred_event)
```


## Checking (approximate) calibration

```{r}
test_pred |>
  cal_plot_windowed(
    truth = class,
    estimate = .pred_event,
    window_size = 0.2,
    step_size = 0.025,
  )
```

## Proceed to the test set -- Automated approach

```{r}
knn_best <- select_best(knn_res, metric = "brier_class")
knn_last_wflow <- finalize_workflow(knn_wflow, knn_best)

knn_test_res <-
  knn_last_wflow |>
  last_fit(sim_split, metrics = cls_mtr)

knn_test_res
```

We can pick out the parts that we want: 

```{r}
knn_final_fit <- knn_test_res |> extract_workflow()
knn_test_pred <- knn_test_res |> collect_predictions()
knn_test_mtr <- knn_test_res |> collect_metrics()

knn_test_mtr
```
