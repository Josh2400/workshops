---
title: "4 - Feature engineering: dummies and embeddings"
subtitle: "Getting More Out of Feature Engineering and Tuning for Machine Learning"
editor_options: 
  chunk_output_type: console
---

We recommend restarting R between each slide deck!

## Setup

```{r}
library(tidymodels)
library(embed)
library(extrasteps)

tidymodels_prefer()
theme_set(theme_bw())
options(pillar.advice = FALSE, pillar.min_title_chars = Inf)

# Load our example data for this section
"https://github.com/tidymodels/workshops/raw/refs/heads/2025-GMOFETML/slides/leaf_data.RData" |>
  url() |>
  load()
```

## Your turn

Load and explore the leaf data.

Make time to look at the `edge` column and think about how one would encode it into numerics.

```{r}
# Your code here!

```

## Your turn

Figure out whether `step_dummy_extract()` or `step_dummy_multi_choice()` is most appropriate on the `edge` variable in `leaf_data` and apply it.

```{r}
# Your code here!

```

## Applying PCA with recipes

Either use the `num_comp` argument.

```{r}
rec <- recipe(mpg ~ ., data = mtcars) |>
  step_normalize(all_predictors()) |>
  step_pca(all_numeric_predictors(), num_comp = 5)
```

Or using a threshold

```{r}
rec <- recipe(mpg ~ ., data = mtcars) |>
  step_normalize(all_predictors()) |>
  step_pca(all_numeric_predictors(), threshold = 0.8)
```

## Your Turn

Apply PCA using `step_pca()` to `leaf_data` data set.

Experiment with different values of `num_comp` and or `threshold`.


```{r}
# Your code here!

```

## Truncated PCA with recipes

```{r}
library(embed)

rec <- recipe(mpg ~ ., data = mtcars) |>
  step_normalize(all_predictors()) |>
  step_pca_truncated(all_numeric_predictors(), num_comp = 5)
```

## Sparse PCA with recipes

```{r}
library(embed)

rec <- recipe(mpg ~ ., data = mtcars) |>
  step_normalize(all_predictors()) |>
  step_pca_sparse(all_numeric_predictors(), num_comp = 5, predictor_prop = 0.8)
```

```{r}
recipe(mpg ~ ., data = mtcars) |>
  step_normalize(all_predictors()) |>
  step_pca_sparse(
    all_numeric_predictors(),
    num_comp = 4,
    predictor_prop = 0.8
  ) |>
  prep() |>
  tidy(number = 2) |>
  pivot_wider(names_from = component, values_from = value) |>
  select(-id)
```


## NNMF with recipes

```{r}
set.seed(1234)

recipe(mpg ~ ., data = mtcars) |>
  step_nnmf_sparse(all_numeric_predictors(), num_comp = 2) |>
  prep() |>
  tidy(number = 1) |>
  pivot_wider(names_from = component, values_from = value) |>
  select(-id)

```

## UMAP with recipes

```{r}
library(embed)
set.seed(1234)

recipe(mpg ~ ., data = mtcars) |>
  step_umap(all_numeric_predictors()) |>
  prep() |>
  bake(NULL)
```

## ISomap with recipes

```{r}
library(embed)
set.seed(1234)

recipe(mpg ~ ., data = mtcars) |>
  step_isomap(all_numeric_predictors(), neighbors = 10) |>
  prep() |>
  bake(NULL)
```

