---
title: "3 - Racing - Classwork"
subtitle: "Getting More Out of Feature Engineering and Tuning for Machine Learning"
editor_options: 
  chunk_output_type: console
---

We recommend restarting R between each slide deck!

## Setup

Setup from deck 2

```{r}
library(tidymodels)
library(finetune)
library(bonsai)

# Max's usual settings:
tidymodels_prefer()
theme_set(theme_bw())
options(
  pillar.advice = FALSE,
  pillar.min_title_chars = Inf
)

# Load our example data for this section
"https://raw.githubusercontent.com/tidymodels/" |>
  paste0("workshops/main/slides/class_data.RData") |>
  url() |>
  load()

set.seed(429)
sim_split <- initial_split(class_data, prop = 0.75, strata = class)
sim_train <- training(sim_split)
sim_test <- testing(sim_split)

set.seed(523)
sim_rs <- vfold_cv(sim_train, v = 10, strata = class)
```

## Boosted trees

```{r}
library(bonsai)

lgbm_spec <-
  boost_tree(
    trees = tune(),
    learn_rate = tune(),
    mtry = tune(),
    min_n = tune(),
    stop_iter = tune()
  ) |>
  set_mode("classification") |>
  # Turn off within-tree parallel processing; it's faster to run
  # the resamples/configurations in parallel
  set_engine("lightgbm", num_threads = 1)

# No preprocessing required:
lgbm_wflow <- workflow(class ~ ., lgbm_spec)
```

## Racing our boosted trees


```{r } 
library(finetune)

# Set this to true to demo
ctrl <- control_race(verbose_elim = FALSE)

# Optimizes on the first metric in the set
cls_mtr <- metric_set(brier_class, roc_auc, sensitivity, specificity)

mirai::daemons(parallel::detectCores() - 1)

set.seed(321)
lgbm_res <-
  lgbm_wflow |>
  tune_race_anova(
    # <- very similar syntax to tune_grid()
    resamples = sim_rs,
    # Let's use a larger grid
    grid = 50,
    control = ctrl,
    metrics = cls_mtr
  )

show_best(lgbm_res, metric = "brier_class")

plot_race(lgbm_res)
```

## Your turn 

- Run `tune_race_anova()` with a different seed and/or a different metric.
- Did you get the same or similar results?

```{r}
# Your code here!

```
